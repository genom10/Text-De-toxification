{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dmitriev Egor\n",
    "e.dmitriev@innopolis.university | BS20-RO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# setting path so we cam import src\n",
    "sys.path.append('..')\n",
    "from src.data.data import *\n",
    "from src.models.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preporcessed dataset\n",
    "df = pd.read_csv('../data/interim/preprocessed.tsv', sep='\\t', index_col=0)\n",
    "sentence_pairs = df[['reference', 'translation']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_LENGTH=64\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 64\n",
    "# MAX_LENGTH = len(max(sentence_pairs.ravel(), key=len))\n",
    "print(f'{MAX_LENGTH=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 190358 sentence pairs\n",
      "Trimmed to 13559 sentence pairs\n",
      "Counting words...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted words:\n",
      "tox 7642\n",
      "detox 7888\n",
      "['you re three grown men who never got to play baseball because you were weird and smelled and sat when you peed'\n",
      " 'you re three grown men who never got a chance to play because you were weird and you got there to pee']\n"
     ]
    }
   ],
   "source": [
    "lang1, lang2 = Lang('tox'), Lang('detox')\n",
    "input_lang, output_lang, pairs = prepareData(lang1, lang2, sentence_pairs, MAX_LENGTH)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['i m famous and you re dead', 'i m famous and you re done'],\n",
      "      dtype=object), array(['the guy is totally irresponsible',\n",
      "       'he s completely irresponsible'], dtype=object), array(['damn i m glad you re back in town yeah me too',\n",
      "       'i m damn glad you re back in town'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "print(pairs[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 190358 sentence pairs\n",
      "Trimmed to 13559 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "tox 7642\n",
      "detox 7888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/genom10/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 53s (- 13m 19s) (5 6%) 0.8363\n",
      "[Errno 17] File exists: '../models'\n",
      "1m 47s (- 12m 30s) (10 12%) 0.5329\n",
      "[Errno 17] File exists: '../models'\n",
      "2m 41s (- 11m 38s) (15 18%) 0.4320\n",
      "[Errno 17] File exists: '../models'\n",
      "3m 34s (- 10m 44s) (20 25%) 0.3540\n",
      "[Errno 17] File exists: '../models'\n",
      "4m 28s (- 9m 51s) (25 31%) 0.2908\n",
      "[Errno 17] File exists: '../models'\n",
      "5m 22s (- 8m 58s) (30 37%) 0.2386\n",
      "[Errno 17] File exists: '../models'\n",
      "6m 17s (- 8m 4s) (35 43%) 0.1970\n",
      "[Errno 17] File exists: '../models'\n",
      "7m 10s (- 7m 10s) (40 50%) 0.1642\n",
      "[Errno 17] File exists: '../models'\n",
      "8m 3s (- 6m 16s) (45 56%) 0.1381\n",
      "[Errno 17] File exists: '../models'\n",
      "8m 56s (- 5m 21s) (50 62%) 0.1181\n",
      "[Errno 17] File exists: '../models'\n",
      "9m 44s (- 4m 25s) (55 68%) 0.1015\n",
      "[Errno 17] File exists: '../models'\n",
      "10m 32s (- 3m 30s) (60 75%) 0.0888\n",
      "[Errno 17] File exists: '../models'\n",
      "11m 21s (- 2m 37s) (65 81%) 0.0778\n",
      "[Errno 17] File exists: '../models'\n",
      "12m 11s (- 1m 44s) (70 87%) 0.0687\n",
      "[Errno 17] File exists: '../models'\n",
      "13m 1s (- 0m 52s) (75 93%) 0.0611\n",
      "[Errno 17] File exists: '../models'\n",
      "13m 50s (- 0m 0s) (80 100%) 0.0546\n",
      "[Errno 17] File exists: '../models'\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 128\n",
    "\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size, sentence_pairs, lang1, lang2, MAX_LENGTH, device)\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, device=device, SOS_token=SOS_token, max_length=MAX_LENGTH).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5, saveDir = '../models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save2file(file, path):\n",
    "    filehandler = open(path, 'wb')\n",
    "    pickle.dump(file, filehandler)\n",
    "\n",
    "def loadFromFile(path):\n",
    "    file_pi2 = open(path, 'rb') \n",
    "    file = pickle.load(file_pi2)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '../models'\n"
     ]
    }
   ],
   "source": [
    "saveModels(encoder, decoder)\n",
    "save2file(input_lang, '../models/lang_tox.obj')\n",
    "save2file(output_lang, '../models/lang_detox.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, device=device, SOS_token=SOS_token, max_length=MAX_LENGTH).to(device)\n",
    "encoder, decoder = loadModels(encoder, decoder, '../models/EncoderRNN_16.0.pt', '../models/AttnDecoderRNN_16.0.pt', )\n",
    "input_lang = loadFromFile('../models/lang_tox.obj')\n",
    "output_lang = loadFromFile('../models/lang_detox.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> shot in the abdomen with a\n",
      "= he was shot in the abdomen by a\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'_IncompatibleKeys' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/genom10/git/PMLDL-Assignment1/notebooks/2.0-teching-torch-seq2seq.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/genom10/git/PMLDL-Assignment1/notebooks/2.0-teching-torch-seq2seq.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m evaluateRandomly(input_lang, output_lang, encoder, decoder, sentence_pairs, device)\n",
      "File \u001b[0;32m~/git/PMLDL-Assignment1/notebooks/../src/data/data.py:215\u001b[0m, in \u001b[0;36mevaluateRandomly\u001b[0;34m(input_lang, output_lang, encoder, decoder, sentence_pairs, device, n)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m>\u001b[39m\u001b[39m'\u001b[39m, pair[\u001b[39m0\u001b[39m])\n\u001b[1;32m    214\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m, pair[\u001b[39m1\u001b[39m])\n\u001b[0;32m--> 215\u001b[0m output_words, _ \u001b[39m=\u001b[39m evaluate(encoder, decoder, pair[\u001b[39m0\u001b[39;49m], input_lang, output_lang, device)\n\u001b[1;32m    216\u001b[0m output_sentence \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(output_words)\n\u001b[1;32m    217\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m<\u001b[39m\u001b[39m'\u001b[39m, output_sentence)\n",
      "File \u001b[0;32m~/git/PMLDL-Assignment1/notebooks/../src/data/data.py:197\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(encoder, decoder, sentence, input_lang, output_lang, device)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m    195\u001b[0m     input_tensor \u001b[39m=\u001b[39m tensorFromSentence(input_lang, sentence, device)\n\u001b[0;32m--> 197\u001b[0m     encoder_outputs, encoder_hidden \u001b[39m=\u001b[39m encoder(input_tensor)\n\u001b[1;32m    198\u001b[0m     decoder_outputs, decoder_hidden, decoder_attn \u001b[39m=\u001b[39m decoder(encoder_outputs, encoder_hidden)\n\u001b[1;32m    200\u001b[0m     _, topi \u001b[39m=\u001b[39m decoder_outputs\u001b[39m.\u001b[39mtopk(\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: '_IncompatibleKeys' object is not callable"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(input_lang, output_lang, encoder, decoder, sentence_pairs, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
